service: improve-v6

plugins:
  - serverless-pseudo-parameters

custom:
  resource-identifier: resources
  jobQueueName: '${self:service}-${self:custom.resource-identifier}-job-queue-${opt:stage, self:provider.stage}'
  jobDefinitionName: '${self:service}-${self:custom.resource-identifier}-job-definition-${opt:stage, self:provider.stage}'

provider:
  lambdaHashingVersion: 20201221 # can be removed in serverless 3
  name: aws
  region: us-east-1
  runtime: nodejs12.x
  timeout: 900
  memorySize: 192
  environment:
    #
    # Customize your deployment here:
    #
    TRAINING_JOB_SCHEDULE: rate(24 hours) # trades off between learning latency and cost
    REWARD_ASSIGNMENT_JOB_SCHEDULE: rate(4 hours) # trades off between learning latency and cost
    TRAINING_IMAGE: 117097735164.dkr.ecr.us-west-2.amazonaws.com/improve_trainer-dev:latest 
    TRAINING_INSTANCE_TYPE: ml.m5.large
    TRAINING_INSTANCE_COUNT: 3
    TRAINING_MAX_RUNTIME_IN_SECONDS: 172800 # 2 days
    FIREHOSE_WORKER_MEMORY_IN_MB: 1024 # must be large enough to unpack the entire firehose buffer into memory. Buffer size is configured in resources/serverless.yml
    REWARD_ASSIGNMENT_WORKER_COUNT: 3
    DEFAULT_REWARD_WINDOW_IN_SECONDS: 172800 # 2 days
    # 
    # End customization
    #
    FEATURE_TRAINING_ROLE_ARN: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.SagemakerExecutionRoleArn}
    FIREHOSE_DELIVERY_STREAM_NAME: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.V4Firehose}
    RECORDS_BUCKET: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.RecordsS3Bucket}
    MODELS_BUCKET: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.ModelsS3Bucket}
    SERVICE: ${self:service}
    STAGE: ${opt:stage, self:provider.stage}
  ecr:
    images:
      assign_rewards:
        path: ./src/assign_rewards/
  httpApi: # FIX MOVE DOWN?
    cors: true
  iamRoleStatements: 
    - Effect: Allow
      Action:
        - "firehose:*"
      Resource: "arn:aws:firehose:*:*:deliverystream/${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.V4Firehose}"
    - Effect: Allow
      Action:
        - "s3:*"
      Resource: 'arn:aws:s3:::${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}-*'
    - Effect: Allow
      Action:
        - "sagemaker:*"
      Resource: '*'
    - Effect: Allow
      Action:
        - "iam:PassRole"
      Resource: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.SagemakerExecutionRoleArn}
    - Effect: Allow
      Action:
        - "lambda:InvokeFunction"
        - "lambda:InvokeAsync"
      Resource: "arn:aws:lambda:${self:provider.region}:*:function:${self:service}-${opt:stage, self:provider.stage}-*"
    - Effect: Allow
      Action:
        - logs:CreateLogGroup
        - logs:CreateLogStream
        - logs:PutLogEvents
        - ec2:CreateNetworkInterface
        - ec2:DescribeNetworkInterfaces
        - ec2:DeleteNetworkInterface
      Resource: "*"
    - Effect: Allow
      Action:
        - elasticfilesystem:ClientMount
        - elasticfilesystem:ClientRootAccess
        - elasticfilesystem:ClientWrite
        - elasticfilesystem:DescribeMountTargets
      Resource: "*"
    - Effect: Allow
      Action:
        - batch:SubmitJob
      Resource: "arn:aws:batch:*:*:*"

package:
  exclude:
    - ./**
  include:
    - 'node_modules/**'
    - 'src/**'

functions:
  track:
    description: Event Tracker HTTP API
    handler: src/track/http_api.track
    timeout: 6
    events:
      - httpApi:
          method: POST
          path: /track
  unpackFirehose:
    description: Ingest Records from S3 to EFS
    handler: src/track/firehose.unpackFirehose
    memorySize: ${self:provider.environment.FIREHOSE_WORKER_MEMORY_IN_MB} 
    events:
      - s3:
          bucket: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.FirehoseS3Bucket}
          existing: true # created in resources/serverless.yml
          event: s3:ObjectCreated:*
    fileSystemConfig:
      localMountPath: /mnt/efs
      arn: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.AccessPointResourceArn}
    vpc:
      securityGroupIds: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.SecurityGroup}
      subnetIds: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.Subnet}
  dispatchRewardAssignmentJobs:
    description: Dispatch Reward Assignment Batch Jobs
    runtime: python3.8
    handler: src/assign_rewards/dispatch_job.lambda_handler
    events:
      - schedule: ${self:provider.environment.REWARD_ASSIGNMENT_JOB_SCHEDULE}
    environment:
      JOB_QUEUE_NAME: ${self:custom.jobQueueName}
      JOB_DEFINITION_NAME: ${self:custom.jobDefinitionName}
  dispatchTrainingJobs:
    description: Dispatch Decision Model Training Jobs
    handler: src/train/train.dispatchTrainingJobs
    events:
      - schedule: ${self:provider.environment.TRAINING_JOB_SCHEDULE}
  unpackModels:
    handler: src/train/unpack_models.unpack
    events:
      - s3:
          bucket: ${cf:${self:service}-${self:custom.resource-identifier}-${opt:stage, self:provider.stage}.RecordsS3Bucket}
          existing: true # created in resources/serverless.yml
          event: s3:ObjectCreated:*
          rules:
            - prefix: models/
            - suffix: model.tar.gz
  forceDockerPush: # serverless actually wants the image to be used to deploy it
    description: Force Serverless to Push Docker Image to ECR
    image:
      name: assign_rewards

