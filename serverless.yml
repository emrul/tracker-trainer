# !!! NOTICE: Modify config/config.yml to customize deployment
custom:
  organization: acme # CHANGE ME BEFORE FIRST DEPLOYMENT
  project: demo # CHANGE ME BEFORE FIRST DEPLOYMENT

provider:
  environment:
    #
    # Customize your deployment here:
    #
    TRAINING_IMAGE: 117097735164.dkr.ecr.us-west-2.amazonaws.com/improve_trainer-dev:latest 
    TRAINING_INSTANCE_TYPE: ml.m5.large
    TRAINING_INSTANCE_COUNT: 3
    TRAINING_MAX_RUNTIME_IN_SECONDS: 172800 # 2 days
    TRAINING_JOB_SCHEDULE: rate(24 hours) # trades off between learning delay and cost
    REWARD_ASSIGNMENT_JOB_SCHEDULE: rate(4 hours)
    REWARD_ASSIGNMENT_WORKER_COUNT: 10
    BATCH_SPOT_BID_PERCENTAGE: 100
    # 
    # End customization
    #
    TRAIN_BUCKET: !Ref TrainS3Bucket
    MODELS_BUCKET: !Ref ModelsS3Bucket
    SERVICE: ${self:service}
    STAGE: ${opt:stage, self:provider.stage}
    
  lambdaHashingVersion: 20201221 # can be removed in serverless v3
  name: aws
  region: us-east-1
  runtime: python3.8
  timeout: 6
  memorySize: 192
  ecr:
    images:
      ingest-firehose:
        path: ./src/ingest_firehose/
      assign-rewards:
        path: ./src/assign_rewards/
  httpApi: # have to specify cors globally for httpApi as of 20210303
    cors: true
  iam:
    role:
      statements: 
        - Effect: Allow
          Action:
            - "firehose:*"
          Resource: { Fn::GetAtt: [Firehose, Arn] }
        - Effect: Allow
          Action:
            - "sagemaker:*"
          Resource: '*'
        - Effect: Allow
          Action:
            - "iam:PassRole"
          Resource: { Fn::GetAtt: [ SagemakerExecutionRole, Arn ] }
        # - Effect: Allow
        #   Action:
        #     - logs:CreateLogGroup
        #     - logs:CreateLogStream
        #     - logs:PutLogEvents
        #     - ec2:CreateNetworkInterface
        #     - ec2:DescribeNetworkInterfaces
        #     - ec2:DeleteNetworkInterface
        #   Resource: "*"
        - Effect: Allow
          Action:
            - batch:SubmitJob
          Resource: "arn:aws:batch:*:*:*"

service: improve-v6-${self:custom.organization}-${self:custom.project}

package:
  exclude:
    - ./**
  include:
    - 'node_modules/**'
    - 'src/**'

functions:
  track:
    description: Event Tracker HTTP API
    handler: src/track/http_api.track
    runtime: nodejs14.x
    events:
      - httpApi:
          method: POST
          path: /track
    environment:
      FIREHOSE_DELIVERY_STREAM_NAME: !Ref Firehose

  dispatchIngestFirehoseFile: # FIX change to dispatchIngestFirehoseJob
    description: Dispatch Ingest Firehose Batch Job
    handler: src/ingest_firehose/dispatch_job.lambda_handler
    events:
      - s3:
          bucket: !Ref FirehoseS3Bucket
          existing: true # retained resource
          event: s3:ObjectCreated:*
    environment:
      JOB_QUEUE: !Ref JobQueue
      JOB_DEFINITION: !Ref IngestFirehoseJobDefinition

  dispatchRewardAssignmentJobs:
    description: Dispatch Reward Assignment Batch Jobs
    handler: src/assign_rewards/dispatch_job.lambda_handler
    events:
      - schedule: ${self:provider.environment.REWARD_ASSIGNMENT_JOB_SCHEDULE}
    environment:
      JOB_QUEUE: !Ref JobQueue
      JOB_DEFINITION: !Ref AssignRewardsJobDefinition

  dispatchTrainingJobs:
    description: Dispatch Decision Model Training Jobs
    handler: src/train/train.dispatchTrainingJobs
    events:
      - schedule: ${self:provider.environment.TRAINING_JOB_SCHEDULE}
    environment:
      TRAINING_ROLE_ARN: { Fn::GetAtt: [ SagemakerExecutionRole, Arn ] }

  unpackModels:
    handler: src/train/unpack_models.unpack
    events:
      - s3:
          bucket: !Ref TrainS3Bucket
          existing: true # created in resources
          event: s3:ObjectCreated:*
          rules:
            - prefix: models/
            - suffix: model.tar.gz
            
  forceDockerPushIngestFirehose: # Serverless wants the image to be used to deploy it
    description: Force Serverless to Push Docker Image to ECR
    image:
      name: ingest-firehose

  forceDockerPushAssignRewards: # Serverless wants the image to be used to deploy it
    description: Force Serverless to Push Docker Image to ECR
    image:
      name: assign-rewards

resources:
  Resources:
      FirehoseToS3Role:
        Type: AWS::IAM::Role
        Properties:
          RoleName: ${self:service}-${opt:stage, self:provider.stage}-FirehoseToS3Role
          AssumeRolePolicyDocument:
            Statement:
            - Effect: Allow
              Principal:
                Service:
                - firehose.amazonaws.com
              Action:
              - sts:AssumeRole
          Policies:
          - PolicyName: FirehoseToS3Policy
            PolicyDocument:
              Statement:
                - Effect: Allow
                  Action:
                  - s3:AbortMultipartUpload
                  - s3:GetBucketLocation
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:ListBucketMultipartUploads
                  - s3:PutObject
                  Resource: "arn:aws:s3:::${self:service}-${opt:stage, self:provider.stage}-firehose"
      SagemakerExecutionRole:
        Type: AWS::IAM::Role
        Properties:
          RoleName: ${self:service}-${opt:stage, self:provider.stage}-SagemakerExecutionRole
          AssumeRolePolicyDocument:
            Statement:
            - Effect: Allow
              Principal:
                Service:
                - firehose.amazonaws.com
              Action:
              - sts:AssumeRole
            - Effect: Allow
              Principal:
                Service:
                - sagemaker.amazonaws.com
              Action:
              - sts:AssumeRole
          ManagedPolicyArns:
          - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
          Policies:
          - PolicyName: SagemakerExecutionPolicy
            PolicyDocument:
              Statement:
                - Effect: Allow
                  Action:
                  - s3:GetObject
                  - s3:DeleteObject
                  - s3:ListBucket
                  - s3:PutObject
                  Resource: "arn:aws:s3:::${self:service}-${opt:stage, self:provider.stage}-**"
      FirehoseS3Bucket:
        Type: 'AWS::S3::Bucket'
        DeletionPolicy: Retain
        Properties:
          BucketName: ${self:service}-${opt:stage, self:provider.stage}-firehose
          IntelligentTieringConfigurations:
            - Id: '${self:service}-${opt:stage, self:provider.stage}-firehose-intelligent-tiering'
              Status: Enabled
              Tierings: # After 30 days intelligent tiering automatically moves to infrequent access tier
                - AccessTier: ARCHIVE_ACCESS
                  Days: 90
                - AccessTier: DEEP_ARCHIVE_ACCESS
                  Days: 180
      Firehose:
        Type: AWS::KinesisFirehose::DeliveryStream
        Properties:
          DeliveryStreamName: ${self:service}-${opt:stage, self:provider.stage}-firehose
          S3DestinationConfiguration:
            BucketARN:
              Fn::Join:
              - ''
              - - 'arn:aws:s3:::'
                - Ref: FirehoseS3Bucket
            BufferingHints:
              IntervalInSeconds: 900 # max value is 900
              SizeInMBs: 128 # max value is 128
            CompressionFormat: "GZIP"
            RoleARN: { Fn::GetAtt: [ FirehoseToS3Role, Arn ] }
      TrainS3Bucket:
        Type: 'AWS::S3::Bucket'
        DeletionPolicy: Retain
        Properties:
          BucketName: ${self:service}-${opt:stage, self:provider.stage}-train
      ModelsS3Bucket:
        Type: 'AWS::S3::Bucket'
        DeletionPolicy: Retain
        Properties:
          BucketName: ${self:service}-${opt:stage, self:provider.stage}-models
      FileSystemResource:
        Type: 'AWS::EFS::FileSystem'
        Properties:
          AvailabilityZoneName: ${self:provider.region}a # EFS One Zone for lower cost
          BackupPolicy:
            Status: DISABLED # data can be re-ingested from Firehose by doing a nop "Edit Metadata" in S3
          Encrypted: true
          LifecyclePolicies:
            - TransitionToIA: AFTER_14_DAYS # when events stop arriving for a history it will transition to infrequent access
          FileSystemPolicy:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "elasticfilesystem:Client*"
                Principal:
                  AWS: "*"
      MountTarget:
        Type: AWS::EFS::MountTarget
        Properties:
          FileSystemId: !Ref FileSystemResource
          SecurityGroups:
            - Ref: SecurityGroup
          SubnetId: !Ref Subnet
        DependsOn: Subnet
      VPC:
        Type: AWS::EC2::VPC
        Properties:
          CidrBlock: 10.0.0.0/16
          EnableDnsHostnames: true
      InternetGateway:
        Type: AWS::EC2::InternetGateway
      RouteTable:
        Type: AWS::EC2::RouteTable
        Properties:
          VpcId: !Ref VPC
      VPCGatewayAttachment:
        Type: AWS::EC2::VPCGatewayAttachment
        Properties:
          VpcId: !Ref VPC
          InternetGatewayId: !Ref InternetGateway
      SecurityGroup:
        Type: AWS::EC2::SecurityGroup
        Properties:
          GroupDescription: EC2 Security Group for instances launched in the VPC by Batch
          VpcId: !Ref VPC
          SecurityGroupIngress:
            - IpProtocol: tcp
              FromPort: 2049 # Allows Batch to connect to EFS
              ToPort: 2049  
              CidrIp: 0.0.0.0/0 
      Subnet:
        Type: AWS::EC2::Subnet
        Properties:
          CidrBlock: 10.0.0.0/24
          VpcId: !Ref VPC
          MapPublicIpOnLaunch: 'True'
          AvailabilityZone: ${self:provider.region}a # match availability zone for EFS One Zone
      Route:
        Type: AWS::EC2::Route
        Properties:
          RouteTableId: !Ref RouteTable
          DestinationCidrBlock: 0.0.0.0/0
          GatewayId: !Ref InternetGateway
      SubnetRouteTableAssociation:
        Type: AWS::EC2::SubnetRouteTableAssociation
        Properties:
          RouteTableId: !Ref RouteTable
          SubnetId: !Ref Subnet
      BatchInstanceProfile:
        Type: AWS::IAM::InstanceProfile
        Properties:
          Roles:
            - Ref: BatchInstanceRole
      BatchInstanceRole:
        Type: AWS::IAM::Role
        Properties:
          AssumeRolePolicyDocument:
            Version: '2012-10-17'
            Statement:
                Effect: Allow
                Principal:
                  Service: 
                    - ec2.amazonaws.com
                Action: sts:AssumeRole
          ManagedPolicyArns:
            - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role
          Policies:
          - PolicyName: BatchInstancePolicy
            PolicyDocument:
              Statement:
                - Effect: Allow
                  Action:
                  - 's3:*'
                  Resource: "arn:aws:s3:::${self:service}-${opt:stage, self:provider.stage}-**"
      BatchServiceRole:
        Type: AWS::IAM::Role
        Properties:
          AssumeRolePolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Principal:
                  Service: 
                  - batch.amazonaws.com
                Action: sts:AssumeRole
          ManagedPolicyArns:
            - arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole
      AmazonEC2SpotFleetRole:
        Type: AWS::IAM::Role
        Properties:
          AssumeRolePolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Principal:
                  Service: 
                  - spotfleet.amazonaws.com
                Action: sts:AssumeRole
          ManagedPolicyArns:
            - arn:aws:iam::aws:policy/service-role/AmazonEC2SpotFleetTaggingRole
      ComputeEnvironment:
        Type: AWS::Batch::ComputeEnvironment
        Properties:
          Type: MANAGED
          ServiceRole: 
            Ref: BatchServiceRole
          ComputeResources:
            Type: SPOT
            AllocationStrategy: SPOT_CAPACITY_OPTIMIZED
            BidPercentage: ${self:provider.environment.BATCH_SPOT_BID_PERCENTAGE} 
            InstanceTypes:
              - optimal
            MinvCpus: 0
            MaxvCpus: 128
            SpotIamFleetRole: !Ref AmazonEC2SpotFleetRole
            InstanceRole: !Ref BatchInstanceProfile
            SecurityGroupIds:
              - Ref: SecurityGroup
            Subnets:
              - Ref: Subnet
          State: ENABLED
      JobQueue:
        Type: AWS::Batch::JobQueue
        Properties:
          ComputeEnvironmentOrder:
            - Order: 1
              ComputeEnvironment: 
                Ref: ComputeEnvironment
          State: ENABLED
          Priority: 2 # 2nd lowest priority
          JobQueueName: '${self:service}-${opt:stage, self:provider.stage}-job-queue'
      IngestFirehoseJobDefinition:
        Type: "AWS::Batch::JobDefinition"
        Properties:
          Type: Container
          ContainerProperties: 
            Memory: 1024 # enough memory to hold a max size (128MB) firehose file
            Vcpus: 1
            Image: !Sub '${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/serverless-${self:service}-${opt:stage, self:provider.stage}:ingest-firehose'
            MountPoints:
              - SourceVolume: efs
                ContainerPath: /mnt/efs
            Volumes:
              - Name: efs
                EfsVolumeConfiguration:
                  FileSystemId: !Ref FileSystemResource
          JobDefinitionName: '${self:service}-${opt:stage, self:provider.stage}-ingest-firehose'
          RetryStrategy: 
            Attempts: 5
      AssignRewardsJobDefinition:
        Type: "AWS::Batch::JobDefinition"
        Properties:
          Type: Container
          ContainerProperties: 
            Memory: 2048
            Vcpus: 1
            Image: !Sub '${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/serverless-${self:service}-${opt:stage, self:provider.stage}:assign-rewards'
            MountPoints:
              - SourceVolume: efs
                ContainerPath: /mnt/efs
            Volumes:
              - Name: efs
                EfsVolumeConfiguration:
                  FileSystemId: !Ref FileSystemResource
          JobDefinitionName: '${self:service}-${opt:stage, self:provider.stage}-assign-rewards'
          RetryStrategy: 
            Attempts: 2 # if the job fails, it will pick up where it left off on the next scheduled execution
